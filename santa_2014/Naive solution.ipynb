{
 "metadata": {
  "name": "",
  "signature": "sha256:c3932c19e5b19cbfa6f14ee712504485d84211857f1a4fd7ba1cc19aa02a143a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "\n",
      "This notebook explores a rather naive solution to the Santa problem: we go through the list of toys in sequence, and for every toy we have the first available elf produce it as soon as possible. This yields a solution that satisfies all the constraints, but it is unlikely to be optimal.\n",
      "\n",
      "The Kaggle website provides an implementation of this naive solution at https://github.com/noahvanhoucke/HelpingSantasHelpers. The goal of this worksheet is to optimize this implementation (it takes about an hour to run). It is helpful but not necessary for running the worksheet if a copy of Kaggle's reference implementation is available in the subdirectory `HelpingSantasHelpers`. \n",
      "\n",
      "The data file `toys_rev2.csv`, which lists the toys that are to be produced, should be in the current directory."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prepare environment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import itertools, os.path, sys, heapq, datetime, csv, numpy, math, cProfile, random, ctypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make it easier to try out stuff, we sample the toys CSV file. We only include one in every thousand toys and save the results in `toys_1000.csv`. Note that the toy IDs are not changed, so the toys have ID 1000, 2000, 3000, ..., 10,000,000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists('toys_1000.csv'):\n",
      "    with open('toys_rev2.csv') as infile, open('toys_1000.csv', 'w') as outfile:\n",
      "        outfile.writelines(itertools.islice(infile, 0, None, 1000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert the CSV file to a .npy file containing the numpy array, as in the \"Load data into numpy\" notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtstart = datetime.datetime(2014,1,1,0,0)\n",
      "if not os.path.exists('toys_1000.npy'):\n",
      "    data = []\n",
      "    with open(\"toys_1000.csv\") as f:\n",
      "        r = csv.reader(f)\n",
      "        header = next(r)\n",
      "        for row in r:\n",
      "            dt = datetime.datetime.strptime(row[1], \"%Y %m %d %H %M\")\n",
      "            delta = dt - dtstart\n",
      "            data.append( [int(delta.total_seconds()/60.0), int(row[2])] )\n",
      "    x = numpy.array(data, dtype=numpy.int32)\n",
      "    numpy.save(\"toys_1000.npy\", x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Reference solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `HelpingSantasHelpers` reference code is Python 2, so it cannot be included in this notebook if we want to run the notebook in Python 3 (as I do). But the reference code can compute the naive solution. \n",
      "\n",
      "We want to compute the naive solution using the sampled data file `toys_1000.csv` and 10 elves (since we reduce the number of toys, I think it also makes sense to reduce the number of elves). Take the script `SantasHelpers_NaiveSolution.py` and at the end, change the value of `NUM_ELVES` to 10 and change `toys_rev2.csv` to `toys_1000.csv`. On my laptop, it takes 3.2 seconds to compute the sample solution and 2.2 seconds to score and check it (so assuming that the full solution takes 1000 times as long, it would take almost an hour to compute it and 40 minutes to score it). The last item in the reference solution reads `\"10000000,6,2062 8 18 11 2,2600\"` meaning that the construction of the last toy is started by elf 6 at 11:02 on 18 Aug 2062. The score is 61343760.1636. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Our own implementation of the naive solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below, which implements the `Elf` class, is copied from the \"Scorer\" notebook. I have made two changes. Firstly, I added an `Elf.__lt__` method which we will need later because we store the Elves in a heapq. Secondly, I changed the `Elf.do_task` method to check whether the Elf is finished at exactly 19:00, and in that case, `available_to_work` is set to 9:00 on the next day. I do not remember why I had to make this change, but as Matt discovered, there is a corner case in the official implementation when the elf finishes at 19:00, and it is easier for me to stipulate that in that case the next task always has to start at (or after) 9:00 at the next day. Note that this is a stricter condition than the official condition, so any solution that we compute will also satisfy the official condition. On the other hand, I don't think it is actually good for an elf to start at 19:00 (unless maybe when it is the last task) so it should not be too much of an issue."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is a script, so we'll tolerate some global variables, and \"magic numbers\"\n",
      "daystarts = 9*60\n",
      "dayends = 19*60\n",
      "minsday = 24*60\n",
      "sanctionedminsday = dayends - daystarts\n",
      "unsanctionedminsday = minsday - sanctionedminsday\n",
      "\n",
      "def ssu_spliter(duration, place, start, end):\n",
      "    \"\"\"Input: duration, place, start, end\n",
      "    where start--end represents an interval of time, place is the current place in the\n",
      "    day, and duration is the total duration.\n",
      "    Intersects [place, place+duration] with the interval, and returns the 'delta' which\n",
      "    is the maximum we can add to place to either get duration==0 or to reach the end of\n",
      "    the interval; returns 0 if no intersection\"\"\"\n",
      "    if start <= place and place < end:\n",
      "        return min(duration, end - place)\n",
      "    return 0\n",
      "\n",
      "def split_sanctioned_unsanctioned(starttime, duration):\n",
      "    \"\"\"Split time period into sanctioned and unsanctioned minutes\n",
      "    Input: starttime, integer, time since 2014 in minutes\n",
      "      duration, integer, time in minutes\n",
      "    Returns: (sanctioned, unsanctioned)\"\"\"\n",
      "    san = 0\n",
      "    unsan = 0\n",
      "    # In any 24 hour period, always the same number of sanctioned and unsanctioned minutes\n",
      "    # so deal with hour days first, and then with remainder\n",
      "    wholedays = duration // minsday\n",
      "    san += wholedays * sanctionedminsday\n",
      "    unsan += wholedays * unsanctionedminsday\n",
      "    duration -= wholedays * minsday\n",
      "    # So now duration < A Day, but still might overlap everything\n",
      "    # Only care about starttime relative to current day now\n",
      "    day_starttime = starttime % minsday\n",
      "    while duration > 0:\n",
      "        # Before start of day\n",
      "        delta = ssu_spliter(duration, day_starttime, 0, daystarts)\n",
      "        unsan += delta\n",
      "        day_starttime = (day_starttime + delta) % minsday\n",
      "        duration -= delta\n",
      "        # Working hours\n",
      "        delta = ssu_spliter(duration, day_starttime, daystarts, dayends)\n",
      "        san += delta\n",
      "        day_starttime = (day_starttime + delta) % minsday\n",
      "        duration -= delta\n",
      "        # After working hours\n",
      "        delta = ssu_spliter(duration, day_starttime, dayends, minsday)\n",
      "        unsan += delta\n",
      "        day_starttime = (day_starttime + delta) % minsday\n",
      "        duration -= delta\n",
      "    return (san,unsan)\n",
      "\n",
      "\n",
      "class ElfExcept(Exception):\n",
      "    pass\n",
      "\n",
      "class Elf:\n",
      "    def __str__(self):\n",
      "        return \"Elf id:{}, productivity:{}, next_free:{}\".format(\n",
      "            self.elfid, self.productivity, self.available_to_work)\n",
      "    def __init__(self, elfid):\n",
      "        self.productivity = 1.0\n",
      "        self.elfid = elfid\n",
      "        # Time the Elf is next able to work\n",
      "        self.available_to_work = 60*9 # Work starts at 9am Jan 1st\n",
      "        self.logging = False # Create a history\n",
      "        if self.logging:\n",
      "            self.history = []\n",
      "    def __lt__(self, other):\n",
      "        return self.elfid < other.elfid\n",
      "    def do_task(self, starttime, duration):\n",
      "        if starttime < self.available_to_work:\n",
      "            raise ElfExcept(\"Elf {} not available to work at time {}.\".format(self.elfid,starttime))\n",
      "        # So now do all the calculation\n",
      "        actual_duration = math.ceil(duration / self.productivity)\n",
      "        san, unsan = split_sanctioned_unsanctioned(starttime, actual_duration)\n",
      "        self.available_to_work = starttime + actual_duration\n",
      "        if self.logging:\n",
      "            log = \"At time {} assigned task of length {} with productivity {}\" \\\n",
      "                  .format(starttime, duration, self.productivity)\n",
      "            log += \" which took me {}, sanctioned:{}, unsanctioned:{}\".format(actual_duration, san, unsan)\n",
      "        # Update productivity\n",
      "        new_prod = (1.02 ** (san/60.0)) * (0.9 ** (unsan/60.0)) * self.productivity\n",
      "        if new_prod < 0.25:\n",
      "            new_prod = 0.25\n",
      "        if new_prod > 4.0:\n",
      "            new_prod = 4.0\n",
      "        self.productivity = new_prod\n",
      "        # Work out rest time needed\n",
      "        # Copied this logic from the official Python code, because of \"bug\"/\"feature\".\n",
      "        if unsan > 0:\n",
      "            num_days_since_jan1 = self.available_to_work // minsday\n",
      "            rest_time = unsan\n",
      "            rest_time_in_working_days = rest_time // sanctionedminsday\n",
      "            rest_time_remaining_minutes = rest_time % sanctionedminsday\n",
      "            local_start = self.available_to_work % minsday\n",
      "            if local_start < daystarts:\n",
      "                local_start = daystarts\n",
      "            elif local_start > dayends:\n",
      "                num_days_since_jan1 += 1\n",
      "                local_start = daystarts\n",
      "            if local_start + rest_time_remaining_minutes > dayends:\n",
      "                rest_time_in_working_days += 1\n",
      "                rest_time_remaining_minutes -= (dayends - local_start)\n",
      "                local_start = daystarts\n",
      "            total_days = num_days_since_jan1 + rest_time_in_working_days\n",
      "            self.available_to_work = total_days * minsday + local_start + rest_time_remaining_minutes\n",
      "        # if available_to_work is exactly 19:00, set it to 9:00 of next day\n",
      "        if self.available_to_work % minsday == dayends:\n",
      "            self.available_to_work += minsday - dayends + daystarts\n",
      "        if self.logging:\n",
      "            log += \" will get off rest time at {}.\".format(self.available_to_work)\n",
      "            self.history.append( log )\n",
      "        return actual_duration"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we have this class, we can easily program the naive solution. The idea of this code comes from  `SantasHelpers_NaiveSolution.py` in Kaggle's reference implementation, but the `Elf` class above makes it quite a bit simpler to implement it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_elves(NUM_ELVES):\n",
      "    \"\"\" Elves are stored in a sorted list using heapq to maintain their order by next available time.\n",
      "    List elements are a tuple of (next_available_time, elf object)\n",
      "    :return: list of elves\n",
      "    \"\"\"\n",
      "    list_elves = []\n",
      "    for i in range(1, NUM_ELVES+1):\n",
      "        elf = Elf(i)\n",
      "        heapq.heappush(list_elves, (elf.available_to_work, elf))\n",
      "    return list_elves\n",
      "\n",
      "\n",
      "def solution_firstAvailableElf(toys, num_elves):\n",
      "    \"\"\" Creates a simple solution where the next available elf is assigned a toy. Elves do not start\n",
      "    work outside of sanctioned hours.\n",
      "    :param toys: array with toys\n",
      "    :param num_elves: number of elves\n",
      "    :return: solution\n",
      "    \"\"\"\n",
      "    myelves = create_elves(num_elves)\n",
      "    solution = numpy.empty((toys.shape[0], 4), dtype=numpy.int32)\n",
      "    \n",
      "    for toy_index, (toy_starttime, toy_duration) in enumerate(toys):\n",
      "        # get next available elf\n",
      "        elf_available_time, current_elf = heapq.heappop(myelves)\n",
      "\n",
      "        work_starttime = max(elf_available_time, toy_starttime)\n",
      "        actual_duration = current_elf.do_task(work_starttime, toy_duration)\n",
      "        \n",
      "        # put elf back in heap\n",
      "        heapq.heappush(myelves, (current_elf.available_to_work, current_elf))\n",
      "\n",
      "        solution[toy_index, 0] = toy_index\n",
      "        solution[toy_index, 1] = current_elf.elfid\n",
      "        solution[toy_index, 2] = work_starttime\n",
      "        solution[toy_index, 3] = actual_duration\n",
      "        \n",
      "    return solution"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Testing our implementation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, load in the data file with the task:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toys = numpy.load('toys_1000.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then, run our implementation of the naive solution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "solution = solution_firstAvailableElf(toys, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print out the last twenty tasks, for comparison with the reference solution. Note in particular the last task, which is the same as was quoted above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for rowid in range(-20, 0):\n",
      "    toyid, elfid, starttime, duration = solution[rowid, :]\n",
      "    starttime_as_date = dtstart + datetime.timedelta(minutes = int(starttime))\n",
      "    print('Toy {:4d}   Elf {:2d}   Starttime {:s}   Duration {:d}'\n",
      "          .format(toyid, elfid, starttime_as_date.strftime(\"%Y %m %d %H %M\"), duration))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Toy 9980   Elf  3   Starttime 2062 08 17 14 05   Duration 133\n",
        "Toy 9981   Elf  6   Starttime 2062 08 17 14 13   Duration 53\n",
        "Toy 9982   Elf 10   Starttime 2062 08 17 14 57   Duration 461\n",
        "Toy 9983   Elf  6   Starttime 2062 08 17 15 06   Duration 298\n",
        "Toy 9984   Elf  9   Starttime 2062 08 17 15 50   Duration 84\n",
        "Toy 9985   Elf  3   Starttime 2062 08 17 16 18   Duration 144\n",
        "Toy 9986   Elf  9   Starttime 2062 08 17 17 14   Duration 43\n",
        "Toy 9987   Elf  1   Starttime 2062 08 17 17 31   Duration 208\n",
        "Toy 9988   Elf  9   Starttime 2062 08 17 17 57   Duration 116\n",
        "Toy 9989   Elf  7   Starttime 2062 08 17 17 59   Duration 150\n",
        "Toy 9990   Elf  2   Starttime 2062 08 17 18 31   Duration 196\n",
        "Toy 9991   Elf  3   Starttime 2062 08 17 18 42   Duration 125\n",
        "Toy 9992   Elf  4   Starttime 2062 08 17 18 47   Duration 6808\n",
        "Toy 9993   Elf  9   Starttime 2062 08 18 09 53   Duration 712\n",
        "Toy 9994   Elf  6   Starttime 2062 08 18 10 04   Duration 58\n",
        "Toy 9995   Elf  7   Starttime 2062 08 18 10 29   Duration 131\n",
        "Toy 9996   Elf  8   Starttime 2062 08 18 10 29   Duration 132\n",
        "Toy 9997   Elf  3   Starttime 2062 08 18 10 47   Duration 181\n",
        "Toy 9998   Elf  1   Starttime 2062 08 18 10 59   Duration 232\n",
        "Toy 9999   Elf  6   Starttime 2062 08 18 11 02   Duration 2600\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can get the reference solution by running the reference implementation of the naive solution on the file `toys_1000.csv`. If we have done this, and stored the reference solution in the file opened below, then this will compare the solution produced by our implementation with the solution of the reference implementation and print the first difference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"HelpingSantasHelpers/sampleSubmission_1000.csv\") as f:\n",
      "    csvreader = csv.reader(f)\n",
      "    header = next(csvreader)\n",
      "    for row_sol in solution:\n",
      "        row_csv = next(csvreader)\n",
      "        elf_csv, starttime_csv, duration_csv = int(row_csv[1]), row_csv[2], int(row_csv[3])\n",
      "        starttime_csv_as_date = datetime.datetime.strptime(starttime_csv, \"%Y %m %d %H %M\")\n",
      "        starttime_csv_as_int = (starttime_csv_as_date - dtstart).total_seconds() / 60\n",
      "        toy_sol, elf_sol, starttime_sol, duration_sol = row_sol\n",
      "        same = elf_csv == elf_sol and starttime_csv_as_int == starttime_sol and duration_csv == duration_sol\n",
      "        if same:\n",
      "            continue\n",
      "        starttime_sol_as_date = dtstart + datetime.timedelta(minutes = int(starttime_sol))\n",
      "        print('Toy {:4d}   Elf {:2d}   Starttime {:s}   Duration {:d}'\n",
      "              .format(toy_sol, elf_sol, starttime_sol_as_date.strftime(\"%Y %m %d %H %M\"), duration_sol))\n",
      "        print('           Elf {:2d}   Starttime {:s}   Duration {:d}'\n",
      "              .format(elf_csv, starttime_csv, duration_csv))\n",
      "        if not same:\n",
      "            break\n",
      "    else:\n",
      "        print('No differences')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "No differences\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us benchmark this implementation; how long does it take?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit solution_firstAvailableElf(toys, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 619 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not bad ... 0.6 seconds on my laptop instead of 3.2 for the official solution, translating to about 10 minutes for the full problem. Next is some profiling to make sure we are not doing anything stupid."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cProfile.run('solution_firstAvailableElf(toys, 10)', sort='cumulative')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         115397 function calls in 0.927 seconds\n",
        "\n",
        "   Ordered by: cumulative time\n",
        "\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "        1    0.000    0.000    0.927    0.927 {built-in method exec}\n",
        "        1    0.000    0.000    0.927    0.927 <string>:1(<module>)\n",
        "        1    0.069    0.069    0.927    0.927 <ipython-input-5-7d5c09f3fea9>:13(solution_firstAvailableElf)\n",
        "    10000    0.404    0.000    0.752    0.000 <ipython-input-4-d53e28f46588>:71(do_task)\n",
        "    10000    0.206    0.000    0.339    0.000 <ipython-input-4-d53e28f46588>:19(split_sanctioned_unsanctioned)\n",
        "    37392    0.113    0.000    0.134    0.000 <ipython-input-4-d53e28f46588>:8(ssu_spliter)\n",
        "    10000    0.088    0.000    0.088    0.000 {built-in method max}\n",
        "    17755    0.020    0.000    0.020    0.000 {built-in method min}\n",
        "    10000    0.011    0.000    0.011    0.000 {built-in method heappop}\n",
        "    10000    0.008    0.000    0.008    0.000 {built-in method ceil}\n",
        "    10010    0.007    0.000    0.007    0.000 {built-in method heappush}\n",
        "      224    0.000    0.000    0.000    0.000 <ipython-input-4-d53e28f46588>:69(__lt__)\n",
        "        1    0.000    0.000    0.000    0.000 <ipython-input-5-7d5c09f3fea9>:1(create_elves)\n",
        "        1    0.000    0.000    0.000    0.000 {built-in method empty}\n",
        "       10    0.000    0.000    0.000    0.000 <ipython-input-4-d53e28f46588>:61(__init__)\n",
        "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nothing unexpected here, it is the routines that do the computations where most of the time is spent. The function `split_sanctioned_unsanctioned` is called 10000 times and about 0.16 seconds is spent inside, so the time per call is 16 microseconds. That seems a bit much. Let's benchmark it individually:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit split_sanctioned_unsanctioned(1020, 2000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 3.02 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That is about five times as fast. I am not sure why; I guess this shows the overhead of the profiler."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Optimizing `split_sanctioned_unsanctioned()`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I think that the function `split_sanctioned_unsanctioned()` can be optimized. In particular, I want to get rid of the three calls to `ssu_spliter()`; that function does so little work that the overhead could be substantial. Furthermore, I do not initialize `san` and `unsan` to zero at the start and I use the `divmod` function. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_sanctioned_unsanctioned_new(starttime, duration):\n",
      "    \"\"\"Split time period into sanctioned and unsanctioned minutes\n",
      "    Input: starttime, integer, time since 2014 in minutes\n",
      "      duration, integer, time in minutes\n",
      "    Returns: (sanctioned, unsanctioned)\"\"\"\n",
      "    # In any 24 hour period, always the same number of sanctioned and unsanctioned minutes\n",
      "    # so deal with hour days first, and then with remainder\n",
      "    wholedays, duration = divmod(duration, minsday)\n",
      "    san = wholedays * sanctionedminsday\n",
      "    unsan = wholedays * unsanctionedminsday\n",
      "    # So now duration < A Day, but still might overlap everything\n",
      "    # Only care about times relative to current day now\n",
      "    day_starttime = starttime % minsday\n",
      "    endtime = day_starttime + duration\n",
      "    if day_starttime < daystarts:\n",
      "        if endtime <= daystarts:\n",
      "            unsan += duration\n",
      "        elif endtime <= dayends:\n",
      "            san += endtime - daystarts\n",
      "            unsan += daystarts - day_starttime\n",
      "        else:\n",
      "            san += sanctionedminsday\n",
      "            unsan += duration - sanctionedminsday\n",
      "    elif day_starttime < dayends:\n",
      "        if endtime <= dayends:\n",
      "            san += duration\n",
      "        elif endtime <= minsday + daystarts:\n",
      "            san += dayends - day_starttime\n",
      "            unsan += endtime - dayends\n",
      "        else:\n",
      "            san += duration - unsanctionedminsday\n",
      "            unsan += unsanctionedminsday\n",
      "    else:\n",
      "        if endtime <= minsday + daystarts:\n",
      "            unsan += duration\n",
      "        elif endtime <= minsday + dayends:\n",
      "            san += endtime - (minsday + daystarts)\n",
      "            unsan += (minsday + daystarts) - day_starttime\n",
      "        else:\n",
      "            san += sanctionedminsday\n",
      "            unsan += duration - sanctionedminsday\n",
      "    return (san,unsan)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using random numbers to check that the new function gives the same results as the old one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for _ in range(100):\n",
      "    starttime = random.randint(1, 10000)\n",
      "    duration = random.randint(1, 10000)\n",
      "    result1 = split_sanctioned_unsanctioned(starttime, duration) \n",
      "    result2 = split_sanctioned_unsanctioned_new(starttime, duration)\n",
      "    if result1 != result2:\n",
      "        print(starttime, duration, result1, result2)\n",
      "        break\n",
      "else:\n",
      "    print(\"Results agree\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Results agree\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And a quick check whether the new function is faster than the old one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit split_sanctioned_unsanctioned(1000, 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 3.41 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit split_sanctioned_unsanctioned_new(1000, 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000000 loops, best of 3: 846 ns per loop\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That looks promising, so we replace the old function with the new function. We recompute the solution to check it is the same, and then we benchmark."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_sanctioned_unsanctioned = split_sanctioned_unsanctioned_new\n",
      "solution2 = solution_firstAvailableElf(toys, 10)\n",
      "assert((solution == solution2).all())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit solution_firstAvailableElf(toys, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 492 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cProfile.run('solution_firstAvailableElf(toys, 10)', sort='cumulative')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         70250 function calls in 0.599 seconds\n",
        "\n",
        "   Ordered by: cumulative time\n",
        "\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "        1    0.000    0.000    0.599    0.599 {built-in method exec}\n",
        "        1    0.000    0.000    0.599    0.599 <string>:1(<module>)\n",
        "        1    0.062    0.062    0.599    0.599 <ipython-input-5-7d5c09f3fea9>:13(solution_firstAvailableElf)\n",
        "    10000    0.328    0.000    0.440    0.000 <ipython-input-4-d53e28f46588>:71(do_task)\n",
        "    10000    0.101    0.000    0.104    0.000 <ipython-input-13-7782ed5f9fbe>:1(split_sanctioned_unsanctioned_new)\n",
        "    10000    0.080    0.000    0.080    0.000 {built-in method max}\n",
        "    10000    0.011    0.000    0.011    0.000 {built-in method heappop}\n",
        "    10000    0.008    0.000    0.008    0.000 {built-in method ceil}\n",
        "    10010    0.007    0.000    0.007    0.000 {built-in method heappush}\n",
        "    10000    0.003    0.000    0.003    0.000 {built-in method divmod}\n",
        "      224    0.000    0.000    0.000    0.000 <ipython-input-4-d53e28f46588>:69(__lt__)\n",
        "        1    0.000    0.000    0.000    0.000 <ipython-input-5-7d5c09f3fea9>:1(create_elves)\n",
        "       10    0.000    0.000    0.000    0.000 <ipython-input-4-d53e28f46588>:61(__init__)\n",
        "        1    0.000    0.000    0.000    0.000 {built-in method empty}\n",
        "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So it is appreciably faster, but not very much: 0.4 seconds instead of 0.6 for the small example; so about seven minutes for the full problem. The profile looks good to me."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Do main computations in C"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In an effort to speed up the naive solution, I tried to program the central computation routine in C. The file `santalib.c` contains a function similar to `Elf.do_task()`, which is called `compute_task()`. The function takes six arguments. Three are input: the duration of the task, when to start it, and the productivity (rating) of the elf (arguments one and two are in the reverse order as in `Elf.do_task()`; sorry about that). The other three are output arguments: how long the elf actually took, when he is available again, and the productivity afterwards.\n",
      "\n",
      "To compile it on Linux, use the command \n",
      "\n",
      "    gcc -O2 -mfpmath=sse -msse2 -fPIC santalib.c -shared -o libsanta.so\n",
      "\n",
      "This produces a library with the name `libsanta.so`. I do not know precisely what the correct flags are. The flags `-mfpmath=sse` and `-msse2` are necessary on my old laptop (32-bits) to produce the same floating-point results in C as in Python on my system (it is crazy to have a competition depend on floating-point arithmetics). The flag `-fPIC` is necessary on my new laptop to get it to work. \n",
      "\n",
      "The Python script file `santalib_tester.py` calls the C function. The result can be compared with the following function call; the numbers agree."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myelf = Elf(1)\n",
      "myelf.productivity = 1.5\n",
      "retval = myelf.do_task(1000, 2000)\n",
      "print('Actual duration = {:d}, available = {:d}, new productivity = {:f}'\n",
      "      .format(retval, myelf.available_to_work, myelf.productivity))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Actual duration = 1334, available = 4014, new productivity = 0.403919\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For further testing, we do some random calls and compare the results with our earlier implementation, allowing for differences because of the 19:00/9:00 silliniess."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_task = ctypes.CDLL('./libsanta.so').compute_task\n",
      "compute_task.retval = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for _ in range(1000):\n",
      "    duration = random.randint(1, 5000)\n",
      "    starttime = random.randint(9*60, 5000)\n",
      "    old_productivity = ctypes.c_double(random.random() * (4-0.25) + 0.25)\n",
      "    actual_duration = ctypes.c_int()\n",
      "    elf_available = ctypes.c_int()\n",
      "    new_productivity = ctypes.c_double()\n",
      "    compute_task(duration, starttime, old_productivity, ctypes.byref(actual_duration),\n",
      "                 ctypes.byref(elf_available), ctypes.byref(new_productivity))\n",
      "    myelf = Elf(1)\n",
      "    myelf.productivity = old_productivity.value\n",
      "    actual_duration2 = myelf.do_task(starttime, duration)\n",
      "    endtime_correct = (elf_available.value == myelf.available_to_work \n",
      "                       or (elf_available.value % minsday == dayends\n",
      "                           and elf_available.value - dayends + minsday + daystarts == myelf.available_to_work))\n",
      "    if (actual_duration.value != actual_duration2 or not endtime_correct\n",
      "        or new_productivity.value != myelf.productivity):\n",
      "        print('Wrong result ... duration = {:d}, starttime = {:d}, old_productivity = {:.17f}'\n",
      "              .format(duration, starttime, old_productivity.value))\n",
      "        print('C code:    actual duration = {:d}, elf_available = {:d}, new_productivity = {:.17f}'\n",
      "              .format(actual_duration.value, elf_available.value, new_productivity.value))\n",
      "        print('Reference: actual duration = {:d}, elf_available = {:d}, new_productivity = {:.17f}'\n",
      "              .format(actual_duration2, myelf.available_to_work, myelf.productivity))\n",
      "        break\n",
      "else:\n",
      "    print('Results agree')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Results agree\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That looks good. We can now re-implement `Elf` to use the new routine. I am also getting rid of the logging facility and other checks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Elf:\n",
      "    def __init__(self, elfid):\n",
      "        self.productivity = 1.0\n",
      "        self.elfid = elfid\n",
      "        self.available_to_work = 60*9 \n",
      "    def __lt__(self, other):\n",
      "        return self.elfid < other.elfid\n",
      "    def do_task(self, starttime, duration):\n",
      "        old_productivity = ctypes.c_double(self.productivity)\n",
      "        actual_duration = ctypes.c_int()\n",
      "        elf_available = ctypes.c_int()\n",
      "        new_productivity = ctypes.c_double()\n",
      "        compute_task(int(duration), int(starttime), old_productivity, ctypes.byref(actual_duration),\n",
      "                     ctypes.byref(elf_available), ctypes.byref(new_productivity))\n",
      "        self.available_to_work = elf_available.value\n",
      "        self.productivity = new_productivity.value\n",
      "        return actual_duration.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us see whether it works."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "solution = solution_firstAvailableElf(toys, 10)\n",
      "for rowid in range(-10, 0):\n",
      "    toyid, elfid, starttime, duration = solution[rowid, :]\n",
      "    starttime_as_date = dtstart + datetime.timedelta(minutes = int(starttime))\n",
      "    print('Toy {:4d}   Elf {:2d}   Starttime {:s}   Duration {:d}'\n",
      "          .format(toyid, elfid, starttime_as_date.strftime(\"%Y %m %d %H %M\"), duration))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Toy 9990   Elf  5   Starttime 2062 08 11 16 35   Duration 151\n",
        "Toy 9991   Elf  4   Starttime 2062 08 11 16 45   Duration 152\n",
        "Toy 9992   Elf  8   Starttime 2062 08 11 16 53   Duration 4934\n",
        "Toy 9993   Elf  2   Starttime 2062 08 11 16 55   Duration 628\n",
        "Toy 9994   Elf  7   Starttime 2062 08 11 16 58   Duration 60\n",
        "Toy 9995   Elf 10   Starttime 2062 08 11 17 07   Duration 109\n",
        "Toy 9996   Elf  7   Starttime 2062 08 11 17 58   Duration 130\n",
        "Toy 9997   Elf  3   Starttime 2062 08 11 18 12   Duration 184\n",
        "Toy 9998   Elf 10   Starttime 2062 08 11 18 56   Duration 169\n",
        "Toy 9999   Elf  5   Starttime 2062 08 12 09 06   Duration 2068\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a few days faster because of the difference in handling elves becoming available at 19:00. Finally, is it faster to run?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit solution_firstAvailableElf(toys, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 149 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yes, we are now down to 0.15 seconds, from 3.2 seconds for the official implementation. That would suggest that is runs in about 2.5 minutes on the full problem. Let's have a go at the full problem now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toys_full = numpy.load('toys_rev2.npy')\n",
      "print(\"{} toys\".format(toys_full.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000000 toys\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -r1 solution_firstAvailableElf(toys_full, 900)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 1: 2min 49s per loop\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So it seems to work reasonably fast."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}